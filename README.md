Tokenizer
=========

Converts long sentences to tokens and filters them for relevant data and rates the words and finds the sentiment value .